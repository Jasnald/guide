\section{Procedures}
\label{sec:procedures}

\textbf{Module path:} \texttt{src/exp\_process/procedures/}

Procedures are the pipeline stages. Each procedure orchestrates core utilities into a named, configurable step: it reads input files, calls core methods, and writes JSON output. Procedures know about experiment types and file paths; core classes do not.

All procedures follow the same pattern: receive a config dataclass, return a \texttt{\{id: Path\}} dict mapping each processed item to its output file. An empty dict means nothing was processed (missing files or empty data).

\subsection{Configuration Dataclasses}
\label{subsec:proc_configs}

\textbf{File:} \texttt{procedures/preprocess.py}

\texttt{BasePreprocessConfig} is the shared base for all configs. It holds \texttt{input\_dir} and \texttt{output\_dir} as \texttt{Path} objects and creates \texttt{output\_dir} on instantiation.

\begin{table}[ht]
\centering
\begin{tabular}{llll}
\hline
\textbf{Config} & \textbf{Field} & \textbf{Default} & \textbf{Description} \\
\hline
\multirow{4}{*}{\texttt{Exp1PreprocessConfig}}
  & \texttt{outlier\_bottom} & \texttt{1.2} & IQR factor for bottom region. \\
  & \texttt{outlier\_top}    & \texttt{1.2} & IQR factor for wall region. \\
  & \texttt{outlier\_general}& \texttt{1.5} & IQR factor for final merged cloud. \\
  & \texttt{step\_threshold} & \texttt{0.6} & Relative x-jump threshold (\%) for step detection. \\
\hline
\multirow{2}{*}{\texttt{Exp2PreprocessConfig}}
  & \texttt{x\_col} & \texttt{0} & Column index for X in raw data array. \\
  & \texttt{z\_col} & \texttt{1} & Column index for Z in raw data array. \\
\hline
\end{tabular}
\caption{Preprocessing config fields.}
\end{table}

\textbf{File:} \texttt{procedures/fitting.py}

\begin{table}[ht]
\centering
\begin{tabular}{llll}
\hline
\textbf{Config} & \textbf{Field} & \textbf{Default} & \textbf{Description} \\
\hline
\multirow{2}{*}{\texttt{Exp1FittingConfig}}
  & \texttt{high\_degree} & \texttt{4} & Degree for the detailed surface fit. \\
  & \texttt{fix\_rules}   & \texttt{None} & Transformation rules for \texttt{DataTransformer}. \\
\hline
\multirow{4}{*}{\texttt{Exp2FittingConfig}}
  & \texttt{high\_degree}   & \texttt{2}    & Degree for the detailed curve fit. \\
  & \texttt{normalize\_x}   & \texttt{True} & Normalize x to $[-1,1]$ before fitting. \\
  & \texttt{ridge\_alpha}   & \texttt{1.0}  & Ridge regularization factor ($\lambda$). \\
  & \texttt{fix\_rules}     & \texttt{None} & Transformation rules for \texttt{DataTransformer}. \\
\hline
\end{tabular}
\caption{Fitting config fields.}
\end{table}

\subsection{preprocess\_exp1}
\label{subsec:preprocess_exp1}

\textbf{File:} \texttt{procedures/preprocess.py}

Processes all sides found in \texttt{input\_dir} through the following sequence:

\begin{enumerate}
    \item \texttt{TShapeParser.load(side\_id)} — loads and stacks bottom+wall measurements for all repetitions.
    \item \texttt{np.vstack} — merges all repetitions into a single point cloud per side.
    \item \texttt{OutlierCleaner.filter\_iqr} — removes outliers on the z axis using \texttt{outlier\_general}.
    \item \texttt{StepSegmenter.find\_steps} — splits the cloud into measurement steps.
    \item \texttt{IOUtils.save\_result} — writes \texttt{\{side\_id\}\_Steps.json}.
\end{enumerate}

Output structure per side:
\begin{lstlisting}[language=Python]
{
    "id": "Side1",
    "total_steps": 12,
    "steps": [
        {"step_number": 1, "point_count": 84, "points": [...]},
        ...
    ]
}
\end{lstlisting}

\subsection{preprocess\_exp2}
\label{subsec:preprocess_exp2}

\textbf{File:} \texttt{procedures/preprocess.py}

Processes all samples found in \texttt{input\_dir}:

\begin{enumerate}
    \item \texttt{RecShapeParser.load(sample\_id)} — loads and averages L/R files.
    \item \texttt{IOUtils.save\_result} — writes \texttt{\{sample\_id\}\_Raw.json}.
\end{enumerate}

No outlier removal or segmentation occurs here for Exp2. The raw merged profile is saved as-is for manual inspection via the GUI before fitting.

\subsection{fit\_exp1}
\label{subsec:fit_exp1}

\textbf{File:} \texttt{procedures/fitting.py}

For each \texttt{*\_Steps.json} in \texttt{input\_dir}:

\begin{enumerate}
    \item Flattens all step points into a single array.
    \item Applies \texttt{DataTransformer.apply} if \texttt{fix\_rules} is set.
    \item Fits a 2D polynomial of degree \texttt{high\_degree} and a degree-1 tilt baseline.
    \item Subtracts baseline from the high-degree model via \texttt{ModelOps.subtract\_coeffs}.
    \item Writes \texttt{\{side\_id\}.json} with the flattened model and points.
\end{enumerate}

The degree-1 subtraction removes measurement tilt, isolating the residual surface shape. The constant \texttt{\_LOW\_DEGREE = 1} is defined at module level and shared across Exp1 and Exp2 fitting.

\subsection{fit\_exp2}
\label{subsec:fit_exp2}

\textbf{File:} \texttt{procedures/fitting.py}

For each \texttt{*\_Raw.json} in \texttt{input\_dir}:

\begin{enumerate}
    \item Applies \texttt{DataTransformer.apply} if \texttt{fix\_rules} is set.
    \item Fits a 1D polynomial of degree \texttt{high\_degree} with optional normalization and Ridge regularization.
    \item Fits a degree-1 baseline and subtracts it.
    \item Writes \texttt{\{sample\_id\}.json} with the flattened model and points.
\end{enumerate}

\subsection{compare\_exp1}
\label{subsec:compare_exp1}

\textbf{File:} \texttt{procedures/comparison.py}

Reads \texttt{Side1.json} and \texttt{Side2.json} from \texttt{input\_dir}, averages their polynomial coefficients via \texttt{ModelOps.average\_models}, and writes \texttt{Average.json}. This is the final step of the Exp1 pipeline, producing a single reference surface from both measurement sides.

\subsection{run\_validation}
\label{subsec:validation}

\textbf{File:} \texttt{procedures/validation.py}

Launches the \texttt{PointCloudViewer} GUI in a blocking Tkinter mainloop. Execution resumes only after the user closes the window. Called between preprocessing and fitting in both pipelines to allow manual removal of remaining outliers before fitting.

\begin{lstlisting}[language=Python]
from exp_process.procedures.validation import run_validation
run_validation(output_dir="data/processed/exp1")
\end{lstlisting}