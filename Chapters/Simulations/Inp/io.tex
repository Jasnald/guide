\section{Input/Output Operations}
\label{sec:inp_io}

\textbf{Scripts:} \texttt{reader.py}, \texttt{writer.py}

These modules abstract the file system interactions, providing specialized readers for the various file formats encountered in the workflow.

\subsection{Readers}
The \texttt{reader.py} module implements specific classes for data ingestion:
\begin{itemize}
    \item \textbf{\texttt{INPReader}:} A simple wrapper around file reading that ensures consistent encoding (UTF-8) and provides line-by-line access to the input deck.
    \item \textbf{\texttt{JSONReader}:} Used to load the polynomial parameters (degree and coefficients) generated in the Preprocessing phase (Module A/B). It handles the conversion of lists back into NumPy arrays for mathematical operations.
    \item \textbf{\texttt{StressReader}:} A CSV parser designed to read external stress field definitions. It robustly handles comment lines (starting with \texttt{\#}) and converts tabular stress data into a dictionary mapping Element IDs to stress vectors.
\end{itemize}

\subsection{Writers}
The \texttt{writer.py} module contains the \texttt{INPWriter} class. While currently a lightweight wrapper for writing lists of strings to disk, it centralizes file encoding handling, ensuring that the modified Input Files generated by the software are always compliant with the text format expected by the Abaqus solver.