\chapter{Residual Stress Analysis (RSA) Workflow}
\label{ch:rs_workflow}

\textbf{Main Orchestrator:} \texttt{src/Simulations/rs\_main.py}

This module orchestrates the final stage of the experimental validation: simulating the redistribution of residual stresses after the cutting process. It is a dependency-aware workflow that links the results from the Contour Method (CMA) directly into a new Finite Element analysis.

\section{Workflow Architecture}

The \texttt{rs\_main.py} script acts as a bridge between the \textit{Inverse Calculation} (Module A/B results) and the \textit{Forward Simulation} (Stress Redistribution). Its execution flow is designed to ensure data consistency between these two physical stages.

\subsection{Dependency Management}
Before starting the stress analysis, the script verifies the existence of the required source data.
\begin{itemize}
    \item \textbf{CMA Execution:} The function accepts a \texttt{run\_cma} flag. If set to \texttt{True}, it imports and executes the \texttt{cm\_main.py} workflow first. This guarantees that the HDF5 files containing the measured stress fields are up-to-date before attempting to map them.
\end{itemize}

\subsection{Geometry and Mesh Generation}
Similar to the CM workflow, it uses the \texttt{GeometryGenerator} to build the target models.

\begin{quote}    
    \textbf{Distinct Geometry:} The geometry for RSA is typically different from the CM geometry (e.g., it may represent the cut part in a relaxed state). The script points to a specific Abaqus script (configured via \texttt{rea\_directory}) to generate these specific meshes.
\end{quote}


\subsection{Stress Mapping (The Bridge)}
This is the core differentiator of this workflow. It integrates the legacy \texttt{ElementProcess} module to perform spatial mapping:

\begin{enumerate}
    \item \textbf{Target Node Extraction:} 
    Calls \texttt{Nodes\_main} (from \texttt{ElementProcess}) to extract the centroids of the newly generated RSA mesh. These centroids act as the "Target Points" for interpolation.
    
    \item \textbf{Field Interpolation:} 
    Instantiates the \texttt{StressProcessor}. It loads the source HDF5 data (from the CM output folder) and uses KDTree algorithms to map the full stress tensor onto the new RSA mesh elements.
    \begin{lstlisting}[language=Python]
    # Mapping source (CM) -> target (RSA)
    proc = StressProcessor(str(config.rea_directory), ...)
    proc.process_all_simulations(str(cm_hdf5_path))
    \end{lstlisting}
    This step effectively transfers the physical state from the first simulation to the second.
\end{enumerate}

\subsection{Injection and Solving}
Once the stresses are mapped and saved as CSVs, the standard pipeline takes over:
\begin{itemize}
    \item \textbf{Injection:} The \texttt{ResidualProcessor} injects the \texttt{*Initial Conditions, type=STRESS} block into the input files.
    \item \textbf{Solving:} The \texttt{INPRunner} submits the jobs to Abaqus to calculate the equilibrium state (redistribution).
\end{itemize}

\chapter{Residual Stress Analysis (RSA) Workflow}
\label{ch:rs_workflow}

\textbf{Main Orchestrator:} \texttt{src/Simulations/rs\_main.py}

This module orchestrates the final stage of the experimental validation: simulating the redistribution of residual stresses after the cutting process. It is a dependency-aware workflow that links the results from the Contour Method (CMA) directly into a new Finite Element analysis.

\section{Workflow Orchestration}
\label{sec:rs_orchestrator}

The \texttt{rs\_main.py} script acts as a bridge between the \textit{Inverse Calculation} (Module A/B results) and the \textit{Forward Simulation} (Stress Redistribution). Its execution flow is designed to ensure data consistency between these two physical stages.

\subsection{Dependency Management}
Before starting the stress analysis, the script verifies the existence of the required source data.
\begin{itemize}
    \item \textbf{CMA Execution:} The function accepts a \texttt{run\_cma} flag. If set to \texttt{True}, it imports and executes the \texttt{cm\_main.py} workflow first. This guarantees that the HDF5 files containing the measured stress fields are up-to-date before attempting to map them.
\end{itemize}

\subsection{Stress Mapping (The Bridge)}
This is the core differentiator of this workflow. It integrates the \texttt{ElementProcess} module to perform spatial mapping between the two distinct geometries:

\begin{enumerate}
    \item \textbf{Target Node Extraction:} 
    Calls \texttt{Nodes\_main} (from \texttt{ElementProcess}) to extract the centroids of the newly generated RSA mesh. These centroids act as the "Target Points" for interpolation.
    
    \item \textbf{Field Interpolation:} 
    Instantiates the \texttt{StressProcessor}. It loads the source HDF5 data (from the CM output folder) and uses KDTree algorithms to map the full stress tensor onto the new RSA mesh elements.
    \begin{lstlisting}[language=Python]
    # Mapping source (CM) -> target (RSA)
    proc = StressProcessor(str(config.rea_directory), ...)
    proc.process_all_simulations(str(cm_hdf5_path))
    \end{lstlisting}
    This step effectively transfers the physical state from the first simulation to the second.
\end{enumerate}

\subsection{Injection and Solving}
Once the stresses are mapped and saved as CSVs, the standard pipeline takes over:
\begin{itemize}
    \item \textbf{Injection:} The \texttt{ResidualProcessor} injects the \texttt{*Initial Conditions, type=STRESS} block into the input files.
    \item \textbf{Solving:} The \texttt{INPRunner} submits the jobs to Abaqus to calculate the equilibrium state (redistribution).
\end{itemize}

\section{Abaqus Geometry Script (The RSA Builder)}
\label{sec:rsa_builder}

\textbf{Script:} \texttt{src/Simulations/rsa/REA\_Extended\_refactored.py}
\newline

Just like \texttt{attempt.py} in the CM workflow, this script represents the "factory floor" for the Residual Stress Analysis. It executes strictly within the \textbf{Abaqus Python 2.7 kernel} to generate the model geometry and simulation steps.

\begin{quote}
    \textbf{Modern Architecture:} Unlike the legacy monolithic design of \texttt{attempt.py}, this script fully utilizes the \textbf{Mixin-based Framework} documented in Chapter \ref{ch:abaqus_modules}. It acts as a controller that coordinates specialized workers (\texttt{MeshSetter}, \texttt{ModelChangeSetter}, etc.) rather than performing all tasks itself.
\end{quote}

\subsection{The \texttt{ContourAnalysisExtended} Class}
This class encapsulates the logic for simulating the material removal process.

\begin{enumerate}
    \item \textbf{Context Binding \& Propagation:} 
    Upon initialization, it creates the geometry using \texttt{GeometrySetterTwo}. Crucially, it uses the \texttt{propagate\_to()} method to share the \texttt{mdb} model context with all other mixins. This ensures that the mesher, the partitioner, and the boundary condition setters all operate on the exact same assembly instance.

    \item \textbf{Dynamic Partitioning (JSON Driven):} 
    It instantiates a \texttt{PlaneGetter} to load cutting plane coordinates (ZX, ZY) from an external JSON file (generated by the Preprocess module). The \texttt{RemoveDatumSetter} then creates physical datum planes and partitions the mesh at these exact coordinates, ensuring the finite elements align perfectly with the cut path.

    \item \textbf{Step Definition (The Physics of Cutting):} 
    Unlike the static analysis of the previous module, this builder defines a multi-step sequence to mimic the experiment:
    \begin{itemize}
        \item \textbf{Step 1 (Material-Removal):} Uses \texttt{ModelChangeSetter} to deactivate elements in the "Remove" set, simulating the physical cut.
        \item \textbf{Step 2 (BC-Removal):} Deactivates the clamping boundary conditions (\texttt{BCBelowSetter}), allowing the part to relax and redistribute stresses.
        \item \textbf{Step 3 (Stabilization):} A final node-release step to ensure numerical convergence.
    \end{itemize}

    \item \textbf{Input Generation:} 
    Finally, it calls the \texttt{JobSetter} not to submit the job, but to generate the \texttt{.inp} file. This file is then handed back to the Python 3 orchestrator (\texttt{rs\_main.py}) for stress injection and execution.
\end{enumerate}