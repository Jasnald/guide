\section{Stage 1: Element Extraction}
\label{sec:ep_extraction}

\textbf{Script:} \texttt{extractor.py}

Parses an Abaqus \texttt{.inp} file and computes element centroids, producing two output files consumed by all downstream stages.

\subsection{Parsing Functions}

\begin{itemize}
    \item \texttt{extract\_elements\_from\_inp(input\_file)} --- scans for the \texttt{*ELEMENT} keyword and returns three arrays: element IDs, element types (e.g.\ \texttt{C3D8R}), and the list of connected node IDs per element.
    \item \texttt{extract\_node\_coordinates(input\_file)} --- scans for the \texttt{*NODE} keyword and returns a \texttt{dict} mapping each node ID to its $(x, y, z)$ coordinates, used for centroid calculation.
    \item \texttt{get\_element\_coordinates(connected\_nodes, node\_coords)} --- averages the coordinates of connected nodes to produce the centroid $(X_{center}, Y_{center}, Z_{center})$ for each element:
\end{itemize}

\begin{equation}
    C_{elem} = \frac{1}{N} \sum_{i=1}^{N} P_{node\_i}
\end{equation}

Nodes missing from \texttt{node\_coords} are skipped; elements with no valid nodes receive \texttt{NaN} centroids.

\subsection{Output Files}

\texttt{save\_element\_info} writes two files to \texttt{output\_dir}:

\begin{table}[ht]
\centering
\begin{tabular}{lll}
\hline
\textbf{File} & \textbf{Format} & \textbf{Contents} \\
\hline
\texttt{elements\_data.txt} & Tab-separated & Element ID, Type, $X/Y/Z$ centroid per row. \\
\texttt{element\_info.txt}  & Plain text     & Total element count, coordinate ranges, type distribution. \\
\hline
\end{tabular}
\caption{Output files from \texttt{extractor.py}.}
\end{table}

\texttt{elements\_data.txt} is the primary input for \texttt{interpolator.py} and \texttt{stress\_mapping.py}. \texttt{element\_info.txt} is used by \texttt{field\_analitic.py} to read the mesh bounding box for synthetic stress generation.